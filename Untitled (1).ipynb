{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vExbeKG7e4Mp"
      },
      "source": [
        "                                                              import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "# Not much diff with jit\n",
        "from numba import jit\n",
        "\"\"\"\n",
        "TL;DR\n",
        "-----------------------------------------------------\n",
        "-----------------------------------------------------\n",
        "-----------------------------------------------------\n",
        "\n",
        "Direct sparse algorithm as described in ICLR 17 paper\n",
        "(implemented using python loops)\n",
        "\n",
        "50% sparsity --> ~25s\n",
        "90% sparsity --> ~9s\n",
        "100% sparsity --> ~38ms\n",
        "PyTorch conv2d --> ~constant @ 4ms for all sparsity levels\n",
        "\n",
        "-----------------------------------------------------\n",
        "-----------------------------------------------------\n",
        "-----------------------------------------------------\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II7gq1Noe4Mu"
      },
      "source": [
        "filter_bank = torch.Tensor([[1, 0, 0], [0, 0, 0], [0, 0, 0]]).view(1, 1, 3, 3).expand(256, 3, -1, -1)\n",
        "filters = copy.deepcopy(filter_bank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rLmF0bxe4Mx"
      },
      "source": [
        "feature_map = torch.rand(3, 64, 64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC4S3Jxye4M1",
        "outputId": "437fb4c3-2578-444c-870b-5378ebb76aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "filter_bank = filter_bank.contiguous().view(256, -1)\n",
        "filter_bank.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 27])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qtMHlJ3e4M5"
      },
      "source": [
        "feature_map_flat = feature_map.view(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFN_AC6Se4M9"
      },
      "source": [
        "# For the streaching operation as described in the paper\n",
        "# Not counting this time in the inference as it is initialization process\n",
        "def generate_idxs(H, W, C, R, S):\n",
        "    passed_idx = 0\n",
        "    idxs = []\n",
        "    for i in range(C):\n",
        "        for j in range(R):\n",
        "            for k in range(S):\n",
        "                idxs.append(passed_idx)\n",
        "                passed_idx += 1\n",
        "            passed_idx = (passed_idx + (W - S))\n",
        "        passed_idx = (i + 1) * (H * W)\n",
        "    return idxs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4NoqUYfe4NB"
      },
      "source": [
        "# Generate 2D sparse weight matrix by streching the weights correctly\n",
        "def generate_sparse_weight(filter_bank, H, W, C, R, S):\n",
        "    idxs = generate_idxs(H, W, C, R, S)\n",
        "    weight = torch.zeros(filter_bank.shape[0], C * H * W)\n",
        "    for i in range(filter_bank.shape[0]):\n",
        "        weight[i, idxs] = filter_bank[i, :]\n",
        "    return weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dywxSjDKe4NE"
      },
      "source": [
        "sparse_weight = generate_sparse_weight(filter_bank, 64, 64, 3, 3, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP81304je4NI"
      },
      "source": [
        "from scipy.sparse import csr_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7WkHh4le4NN"
      },
      "source": [
        "# CSR format in scipy. Torch sparse use COO format.\n",
        "sparse_csr_weight = csr_matrix(sparse_weight.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZZ0sREe4NU"
      },
      "source": [
        "# Obtain flattened index from c, r, s, H, W\n",
        "def layout_func_chw(c, r, s, H, W):\n",
        "    return (c * H + r) * W + s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlVUDy2Ie4NY"
      },
      "source": [
        "# Main algorithm as described in the paper\n",
        "# I am looping element by element using python for loops which are damn inefficient!\n",
        "# Need to write C++ extension for this algo\n",
        "def sparse_convolution(sparse_csr_weight, feature_map, C, H, W):\n",
        "    out = np.zeros((sparse_csr_weight.shape[0], H-2, W-2))\n",
        "    for n in range(sparse_csr_weight.shape[0]):\n",
        "        for (off, coeff) in zip(sparse_csr_weight[n].indices, sparse_csr_weight[n].data):\n",
        "            for y in range(0, H - 2):\n",
        "                for x in range(0, W - 2):\n",
        "                    out[n, y, x] += coeff * feature_map[off + layout_func_chw(0, y, x, H, W)]\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G0vpVPke4Nd",
        "outputId": "3392d09b-2595-4851-edd9-f9225b79f4b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%timeit out = sparse_convolution(sparse_csr_weight, feature_map_flat.numpy(), 3, 64, 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 9.08 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo6ToCX7e4Ng",
        "outputId": "b3c4e30f-e6f8-4873-d19e-8c74005c0ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "feature_map.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McGw_AHRe4Nj"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maOcWkd5e4Nm",
        "outputId": "d8b3d00d-4236-470d-a68b-c13a271f7677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "filter_bank.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-af5fbc017ae6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfilter_bank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'filter_bank' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ci0olGre4Np"
      },
      "source": [
        "filter_bank = torch.Tensor([[1, 0, 0], [0, 0, 0], [0, 0, 0]]).view(1, 1, 3, 3).expand(256, 3, -1, -1).double()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX2MH27He4Nr",
        "outputId": "2742104b-e13a-4616-f248-889f750549f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Torch conv2d is ~2K times fast than our pure python looping algo for ~90% sparse kernels\n",
        "%timeit out_torch = F.conv2d(torch.unsqueeze(feature_map.double(), dim=0), filter_bank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 27.72 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 3: 4.2 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq7UEIHCe4Ny"
      },
      "source": [
        "out = sparse_convolution(sparse_csr_weight, feature_map_flat.numpy(), 3, 64, 64)\n",
        "out_torch = F.conv2d(torch.unsqueeze(feature_map.double(), dim=0), filter_bank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NFG8vI-e4N1",
        "outputId": "79a73d02-5283-4e05-94d5-8a25ec6d94c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Just to confirm that algo produce correct convolution output\n",
        "(out_torch.numpy().squeeze() - out).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMNtmo3ee4N5"
      },
      "source": [
        "# Check speedup for all zeros matrix\n",
        "filter_bank = torch.Tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0]]).view(1, 1, 3, 3).expand(256, 3, -1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XG-xrfNKe4N_"
      },
      "source": [
        "sparse_weight = generate_sparse_weight(filter_bank.contiguous().view(256, -1), 64, 64, 3, 3, 3)\n",
        "sparse_csr_weight = csr_matrix(sparse_weight.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_ZB-L0qe4OE",
        "outputId": "fc2c9d05-5f37-47cf-fcda-53ad6ca7ae98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# ~230 times speedup when moving from ~90% sparsity to 100% sparsity\n",
        "# For 50% sparsity though, our algo takes ~25s hence from 50% to 90% we achieve ~2.8 times speedup only\n",
        "# This indicates that algorithm speeds up when we increase sparsity\n",
        "%timeit out = sparse_convolution(sparse_csr_weight, feature_map_flat.numpy(), 3, 64, 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 38.5 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEfQQ_wke4OH",
        "outputId": "b123e1f3-f14d-4c9b-97cf-2f3b129e501a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Pytorch timing remains almost same as it does nothing special to \n",
        "# consider sparsity\n",
        "% timeit out_torch = F.conv2d(torch.unsqueeze(feature_map.double(), dim=0), filter_bank.double())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 4.46 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWG8ZnD1k-i5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "c5a83d79-2186-474c-89ca-dbbbb24e62bc"
      },
      "source": [
        "model.save('model.h5')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-596723284980>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from flask import flask,request,jsonity,render_template\n",
        "import pickle\n",
        "app= Flask(_name_)\n",
        "from tensorflow.keras.models import load_model\n",
        "model=pickle.load('model.h5')\n"
      ],
      "metadata": {
        "id": "haCQqu6OP3Iu",
        "outputId": "3a1d9779-73ea-434e-c833-4380534b2508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-96d9164eb2f9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjsonity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrender_template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_name_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'flask' from 'flask' (/usr/local/lib/python3.9/dist-packages/flask/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def home()\n",
        "  return render_template('Demo2.html')\n",
        "def y_predict();\n",
        "for rendering results on HTMLGUI\n",
        "min1=[290.0,92_0,1.0,1.0,6.8,0.0]\n",
        "max1=[340.0,120.0,5.0,5.0,5.0,9.92,1.0]\n",
        "k=[float(x) for x in request.formvalues()]\n",
        "p=[]\n",
        "for i in range(7):\n",
        "  1=(k[i]-min1[i])/(max1[1]-min1[1]\n",
        "  p.append(1)\n",
        "  prediction=mode1.predict([o\n",
        "  print(prediction)\n",
        "  output=prediction[0]\n",
        "  if(output=Flase):\n",
        "    return render_teaplate('nochance.html,prediction_tedt='you donthave a chance of gettin\n",
        "                           else\\:\n",
        "                           return render_template('chance.html',predition_text='You have a chance of gettin admine\n",
        "                           if _name_-\"_-min__\":\n",
        "                             app.run(debugt-Flase)\n",
        "  if_name_==\"_main_\":\n",
        "    app.run(debug=false)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                            ])"
      ],
      "metadata": {
        "id": "7rDfHRZIIHxs",
        "outputId": "b3469951-6b44-4a9a-801c-46ccd02670eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-63ff7b8a38e0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def home()\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}